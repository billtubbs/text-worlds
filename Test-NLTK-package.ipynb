{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2588679-4eb9-4644-8c16-68e5c29094c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384a212b-7b06-41eb-a5ce-112ff7458a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39376b23-0607-4100-83d5-1f60314c0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Go north\",\n",
    "    \"Go into the cave\",\n",
    "    \"Pick up the map\",\n",
    "    \"Open the green door\",\n",
    "    \"Unlock the wooden door with the large rusty key\",\n",
    "    \"Put the map on the table\",\n",
    "    \"Go to sleep\",\n",
    "    \"Lie down on the bed and go to sleep\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e623f4cc-cc6d-44c6-972f-e92bc3ff2622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go north'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = sentences[0]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce7bfcf-c8e8-421a-bbc2-b27e6c947a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tags(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    return pos_tags\n",
    "\n",
    "tags = get_pos_tags(\"The quick brown fox jumped over the lazy dog.\")\n",
    "assert tags == [\n",
    "    ('The', 'DT'),\n",
    "    ('quick', 'JJ'),\n",
    "    ('brown', 'NN'),\n",
    "    ('fox', 'NN'),\n",
    "    ('jumped', 'VBD'),\n",
    "    ('over', 'IN'),\n",
    "    ('the', 'DT'),\n",
    "    ('lazy', 'JJ'),\n",
    "    ('dog', 'NN'),\n",
    "    ('.', '.')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90be4ae2-35b1-4249-9941-2e1e424dd542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Go', 'NNP'), ('north', 'RB')]\n",
      "[('Go', 'VB'), ('into', 'IN'), ('the', 'DT'), ('cave', 'NN')]\n",
      "[('Pick', 'NNP'), ('up', 'RP'), ('the', 'DT'), ('map', 'NN')]\n",
      "[('Open', 'VB'), ('the', 'DT'), ('green', 'JJ'), ('door', 'NN')]\n",
      "[('Unlock', 'IN'), ('the', 'DT'), ('wooden', 'JJ'), ('door', 'NN'), ('with', 'IN'), ('the', 'DT'), ('large', 'JJ'), ('rusty', 'NN'), ('key', 'NN')]\n",
      "[('Put', 'VB'), ('the', 'DT'), ('map', 'NN'), ('on', 'IN'), ('the', 'DT'), ('table', 'NN')]\n",
      "[('Go', 'VB'), ('to', 'TO'), ('sleep', 'VB')]\n",
      "[('Lie', 'NNP'), ('down', 'RB'), ('on', 'IN'), ('the', 'DT'), ('bed', 'NN'), ('and', 'CC'), ('go', 'VB'), ('to', 'TO'), ('sleep', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    print(get_pos_tags(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf32129-fab8-4656-8d08-7f8c95840691",
   "metadata": {},
   "source": [
    "Problem:\n",
    " - [NLTK Thinks that Imperatives are Nouns](https://stackoverflow.com/q/9406093/1609514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4513845e-d027-4ae7-bcdf-0efba65d90c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Go', 'VBP'), ('north', 'JJ')]\n",
      "[('Go', 'VBP'), ('into', 'IN'), ('the', 'DT'), ('cave', 'NN')]\n",
      "[('Pick', 'VBP'), ('up', 'RP'), ('the', 'DT'), ('map', 'NN')]\n",
      "[('Open', 'VBP'), ('the', 'DT'), ('green', 'JJ'), ('door', 'NN')]\n",
      "[('Unlock', 'VBP'), ('the', 'DT'), ('wooden', 'JJ'), ('door', 'NN'), ('with', 'IN'), ('the', 'DT'), ('large', 'JJ'), ('rusty', 'NN'), ('key', 'NN')]\n",
      "[('Put', 'VBP'), ('the', 'DT'), ('map', 'NN'), ('on', 'IN'), ('the', 'DT'), ('table', 'NN')]\n",
      "[('Go', 'VBP'), ('to', 'TO'), ('sleep', 'VB')]\n",
      "[('Lie', 'VBP'), ('down', 'RP'), ('on', 'IN'), ('the', 'DT'), ('bed', 'NN'), ('and', 'CC'), ('go', 'VB'), ('to', 'TO'), ('sleep', 'VB')]\n",
      "CPU times: user 6.94 ms, sys: 2.65 ms, total: 9.59 ms\n",
      "Wall time: 7.89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_pos_tags(sentence):\n",
    "    words = ['You'] + word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    return pos_tags[1:]\n",
    "\n",
    "for sent in sentences:\n",
    "    print(get_pos_tags(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd0fdd-3743-45f2-8319-7e359d0cf848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0dedaa-c803-439e-99da-0e1ced653e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stanford-postagger-gui.sh',\n",
       " 'sample-output.txt',\n",
       " 'stanford-postagger.jar',\n",
       " '.DS_Store',\n",
       " 'build.xml',\n",
       " 'stanford-postagger-gui.bat',\n",
       " 'TaggerDemo.java',\n",
       " 'models',\n",
       " 'stanford-postagger.bat',\n",
       " 'TaggerDemo2.java',\n",
       " 'sample-input.txt',\n",
       " 'stanford-postagger-4.2.0-sources.jar',\n",
       " 'stanford-postagger.sh',\n",
       " 'stanford-postagger-4.2.0-javadoc.jar',\n",
       " 'README.txt',\n",
       " 'stanford-postagger-4.2.0.jar',\n",
       " 'LICENSE.txt',\n",
       " 'data']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir('../stanford-tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1501cb2-dbd8-48fe-9e22-bd0a5983176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import StanfordTagger\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "\n",
    "st = StanfordPOSTagger('../stanford-tagger/models/english-bidirectional-distsim.tagger', path_to_jar='../stanford-tagger/stanford-postagger.jar') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d745545-9442-4e92-8503-5c2208089ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Go', 'VB'), ('north', 'RB')]\n",
      "[('Go', 'VB'), ('into', 'IN'), ('the', 'DT'), ('cave', 'NN')]\n",
      "[('Pick', 'VB'), ('up', 'RP'), ('the', 'DT'), ('map', 'NN')]\n",
      "[('Open', 'VB'), ('the', 'DT'), ('green', 'JJ'), ('door', 'NN')]\n",
      "[('Unlock', 'VB'), ('the', 'DT'), ('wooden', 'JJ'), ('door', 'NN'), ('with', 'IN'), ('the', 'DT'), ('large', 'JJ'), ('rusty', 'JJ'), ('key', 'NN')]\n",
      "[('Put', 'VB'), ('the', 'DT'), ('map', 'NN'), ('on', 'IN'), ('the', 'DT'), ('table', 'NN')]\n",
      "[('Go', 'VB'), ('to', 'TO'), ('sleep', 'VB')]\n",
      "[('Lie', 'NN'), ('down', 'RP'), ('on', 'IN'), ('the', 'DT'), ('bed', 'NN'), ('and', 'CC'), ('go', 'VB'), ('to', 'IN'), ('sleep', 'NN')]\n",
      "CPU times: user 42.9 ms, sys: 112 ms, total: 155 ms\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_pos_tags(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    return st.tag(words)\n",
    "\n",
    "for sent in sentences:\n",
    "    print(get_pos_tags(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bafa21c-db1a-4129-a73d-60f5588cd6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1484.2105263157894"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Times slower\n",
    "14.1 * 1000 / 9.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26c9d7ba-268e-45f6-9c34-b531521e9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91237463-cd5f-4c93-922e-857978a14a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('You', 'PRP'), ('Go', 'VBP'), ('north', 'JJ')]\n",
      "[('You', 'PRP'), ('Go', 'VBP'), ('into', 'IN'), ('the', 'DT'), ('cave', 'NN')]\n",
      "[('You', 'PRP'), ('Pick', 'VBP'), ('up', 'RP'), ('the', 'DT'), ('map', 'NN')]\n",
      "[('You', 'PRP'), ('Open', 'VBP'), ('the', 'DT'), ('green', 'JJ'), ('door', 'NN')]\n",
      "[('You', 'PRP'), ('Unlock', 'VBP'), ('the', 'DT'), ('wooden', 'JJ'), ('door', 'NN'), ('with', 'IN'), ('the', 'DT'), ('large', 'JJ'), ('rusty', 'NN'), ('key', 'NN')]\n",
      "[('You', 'PRP'), ('Put', 'VBP'), ('the', 'DT'), ('map', 'NN'), ('on', 'IN'), ('the', 'DT'), ('table', 'NN')]\n",
      "[('You', 'PRP'), ('Go', 'VBP'), ('to', 'TO'), ('sleep', 'VB')]\n",
      "[('You', 'PRP'), ('Lie', 'VBP'), ('down', 'RP'), ('on', 'IN'), ('the', 'DT'), ('bed', 'NN'), ('and', 'CC'), ('go', 'VB'), ('to', 'TO'), ('sleep', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "def get_pos_tags(sentence):\n",
    "    words = ['You'] + word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    return pos_tags\n",
    "\n",
    "for sent in sentences:\n",
    "    print(get_pos_tags(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b328e1eb-a5f1-47c4-81c7-22579af5a3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP door/NN))\n",
      "(S (NP the/DT door/NN))\n",
      "(S (NP green/JJ door/NN))\n",
      "(S (NP that/DT green/JJ door/NN))\n",
      "(S (NP a/DT bright/JJ green/JJ door/NN))\n",
      "(S (NP large/JJ wooden/JJ door/NN))\n",
      "(S (NP wooden/JJ leg/NN))\n",
      "(S my/PRP$ (NP leg/NN))\n",
      "(S (NP wooden/JJ leg/NN))\n"
     ]
    }
   ],
   "source": [
    "def get_pos_tags(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    return pos_tags\n",
    "\n",
    "def parse_chunk(tags, grammar):\n",
    "    chunk_parser = nltk.RegexpParser(grammar)\n",
    "    tree = chunk_parser.parse(tags)\n",
    "    return tree\n",
    "\n",
    "sentences = [\n",
    "    \"door\",\n",
    "    \"the door\",\n",
    "    \"green door\",\n",
    "    \"that green door\",\n",
    "    \"a bright green door\",\n",
    "    \"large wooden door\",\n",
    "    \"wooden leg\",\n",
    "    \"my leg\",\n",
    "    \"wooden leg\"\n",
    "]\n",
    "grammar = r\"NP: {<DT|PP\\$>?<JJ>*<NN>}\"\n",
    "for sentence in sentences:\n",
    "    tree = parse_chunk(get_pos_tags(sentence), grammar)\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e06d4b2-d9e6-4a79-8786-a71052208a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP the bright green envelope)\n"
     ]
    }
   ],
   "source": [
    "np1 = nltk.Tree('NP', ['the', 'bright', 'green', 'envelope'])\n",
    "print(np1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1217f31f-8d71-436a-abd1-f01c0beab1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(VP pick up)\n"
     ]
    }
   ],
   "source": [
    "vp1 = nltk.Tree('VP', ['pick', 'up'])\n",
    "print(vp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c64284a-26ef-4a24-9275-33128deede4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PRP$ You)\n"
     ]
    }
   ],
   "source": [
    "p1 = nltk.Tree('PRP$', ['You'])\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c6ae0d7-5d05-4eaa-9420-9ecea1fb6e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (PRP$ You) (VP pick up) (NP the bright green envelope))\n"
     ]
    }
   ],
   "source": [
    "tree = nltk.Tree('S', [p1, vp1, np1])\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "649ea877-1f6d-4f0f-864d-027deb75bbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( S ( PRP$ You ) ( VP pick up ) ( NP the bright green envelope ) ) "
     ]
    }
   ],
   "source": [
    "def traverse(t):\n",
    "    try:\n",
    "        t.label()\n",
    "    except AttributeError:\n",
    "        print(t, end=\" \")\n",
    "    else:\n",
    "        # Now we know that t.node is defined\n",
    "        print('(', t.label(), end=\" \")\n",
    "        for child in t:\n",
    "            traverse(child)\n",
    "        print(')', end=\" \")\n",
    "\n",
    "traverse(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76911cc8-932c-42cd-84cc-cbc30ad316ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/billtubbs/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1cc5cc2-9989-4fdc-a5ec-b6439f7dec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/billtubbs/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab85317b-fe0d-4465-ba6f-157b9c6a2f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S you/PRP pick/VBP up/RP the/DT bright/JJ green/JJ envelope/NN)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"you pick up the bright green envelope\"\n",
    "words = word_tokenize(sentence)\n",
    "tags = nltk.pos_tag(words)\n",
    "tree = nltk.ne_chunk(tags, binary=True)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ac2f536-f625-4653-9a41-eac9096fab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( S ('you', 'PRP') ('pick', 'VBP') ('up', 'RP') ('the', 'DT') ('bright', 'JJ') ('green', 'JJ') ('envelope', 'NN') ) "
     ]
    }
   ],
   "source": [
    "traverse(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fe98334-1ca9-4547-86a1-fc542271bdb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe bright green envelope\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m words \u001b[38;5;241m=\u001b[39m word_tokenize(sentence)\n\u001b[0;32m----> 3\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChartParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursivedescent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m trees \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mnbest_parse(sent, trace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nltk/lib/python3.11/site-packages/nltk/parse/chart.py:1397\u001b[0m, in \u001b[0;36mChartParser.__init__\u001b[0;34m(self, grammar, strategy, trace, trace_chart_width, use_agenda, chart_class)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axioms \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_rules \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1397\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rule \u001b[38;5;129;01min\u001b[39;00m strategy:\n\u001b[1;32m   1398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rule\u001b[38;5;241m.\u001b[39mNUM_EDGES \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1399\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axioms\u001b[38;5;241m.\u001b[39mappend(rule)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not iterable"
     ]
    }
   ],
   "source": [
    "sentence = \"the bright green envelope\"\n",
    "words = word_tokenize(sentence)\n",
    "parser = nltk.ChartParser(grammar, nltk.parse.BU_STRATEGY)\n",
    "trees = parser.nbest_parse(sent, trace=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b075805-21ef-48e8-b391-a292a43066c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk.parse in nltk:\n",
      "\n",
      "NAME\n",
      "    nltk.parse - NLTK Parsers\n",
      "\n",
      "DESCRIPTION\n",
      "    Classes and interfaces for producing tree structures that represent\n",
      "    the internal organization of a text.  This task is known as \"parsing\"\n",
      "    the text, and the resulting tree structures are called the text's\n",
      "    \"parses\".  Typically, the text is a single sentence, and the tree\n",
      "    structure represents the syntactic structure of the sentence.\n",
      "    However, parsers can also be used in other domains.  For example,\n",
      "    parsers can be used to derive the morphological structure of the\n",
      "    morphemes that make up a word, or to derive the discourse structure\n",
      "    for a set of utterances.\n",
      "    \n",
      "    Sometimes, a single piece of text can be represented by more than one\n",
      "    tree structure.  Texts represented by more than one tree structure are\n",
      "    called \"ambiguous\" texts.  Note that there are actually two ways in\n",
      "    which a text can be ambiguous:\n",
      "    \n",
      "        - The text has multiple correct parses.\n",
      "        - There is not enough information to decide which of several\n",
      "          candidate parses is correct.\n",
      "    \n",
      "    However, the parser module does *not* distinguish these two types of\n",
      "    ambiguity.\n",
      "    \n",
      "    The parser module defines ``ParserI``, a standard interface for parsing\n",
      "    texts; and two simple implementations of that interface,\n",
      "    ``ShiftReduceParser`` and ``RecursiveDescentParser``.  It also contains\n",
      "    three sub-modules for specialized kinds of parsing:\n",
      "    \n",
      "      - ``nltk.parser.chart`` defines chart parsing, which uses dynamic\n",
      "        programming to efficiently parse texts.\n",
      "      - ``nltk.parser.probabilistic`` defines probabilistic parsing, which\n",
      "        associates a probability with each parse.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api\n",
      "    bllip\n",
      "    chart\n",
      "    corenlp\n",
      "    dependencygraph\n",
      "    earleychart\n",
      "    evaluate\n",
      "    featurechart\n",
      "    generate\n",
      "    malt\n",
      "    nonprojectivedependencyparser\n",
      "    pchart\n",
      "    projectivedependencyparser\n",
      "    recursivedescent\n",
      "    shiftreduce\n",
      "    stanford\n",
      "    transitionparser\n",
      "    util\n",
      "    viterbi\n",
      "\n",
      "FILE\n",
      "    /Users/billtubbs/opt/anaconda3/envs/nltk/lib/python3.11/site-packages/nltk/parse/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c06b9ed-873d-4212-bb99-37b53bdd9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_string = \"\"\"(S (NP-SBJ (NP (QP (IN at) (JJS least) (CD nine) (NNS tenths)) ) (PP (IN of) (NP (DT the) (NNS students) ))) (VP (VBD passed)))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6e395a9-d367-4814-b6eb-b0c575abfcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(S (NP-SBJ (NP (QP (IN at) (JJS least) (CD nine) (NNS tenths)) ) (PP (IN of) (NP (DT the) (NNS students) ))) (VP (VBD passed)))'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c79a6d24-7872-4995-a666-9a1ac15c37ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (QP (IN at) (JJS least) (CD nine) (NNS tenths)))\n",
      "    (PP (IN of) (NP (DT the) (NNS students))))\n",
      "  (VP (VBD passed)))\n"
     ]
    }
   ],
   "source": [
    "t = nltk.Tree.fromstring(treebank_string)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9082ff1-e6eb-4411-8548-34f0d980d357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")\n",
    "\n",
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9dce1e71-018f-42ff-a81a-a885cdf5b4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP You)\n",
      "  (VP\n",
      "    (V sit)\n",
      "    (PP (P on) (NP (Det the) (AP (J big) (AP (J wooden) (N bed)))))))\n"
     ]
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det AP | N PP | AP PP | NP PP | 'You'\n",
    "VP -> V NP | V PP | V NP PP\n",
    "AP -> J N | J AP\n",
    "Det -> 'the' | 'a' | 'an' | 'my'\n",
    "N -> 'bed' | 'door' | 'key' | 'handle'\n",
    "V -> 'sit' | 'open' | 'close' | 'unlock' | 'go'\n",
    "P -> 'on' | 'in' | 'with' | 'to'\n",
    "J -> 'big' | 'wooden'\n",
    "\"\"\")\n",
    "\n",
    "sent = ['You', 'sit', 'on', 'the', 'big', 'wooden', 'bed']\n",
    "#sent = ['You', 'open', 'the', 'wooden', 'door', 'with', 'the', 'handle']\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe812f-f0be-4d92-9eb5-ead759730c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a3ac15-6112-4a34-bb41-a6bb2071ecb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b37e38-6719-44a1-bc79-1c6a100f61a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20aa3a-a3f2-4f4a-b127-d6220b997e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nltk",
   "language": "python",
   "name": "nltk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
